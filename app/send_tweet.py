#!/usr/bin/env python3
"""
X (Twitter) Share via Gmail to Teams Bridge
Androidã®Xã‚¢ãƒ—ãƒªã‹ã‚‰å…±æœ‰ã—ãŸãƒ¡ãƒ¼ãƒ«ã‚’å‡¦ç†ã—ã¦Teamsã«æŠ•ç¨¿
"""

import os
import pytz
import requests
import re
import base64
import pickle
import random
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from dataclasses import dataclass
from pathlib import Path

# Gmail API imports
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# Import setup_logger from util.log
from util.log import setup_logger

# Setup logging
logger = setup_logger(__name__)

# Gmail API ã‚¹ã‚³ãƒ¼ãƒ—
SCOPES = [
    'https://www.googleapis.com/auth/gmail.readonly',
    'https://www.googleapis.com/auth/gmail.modify'  # æ—¢èª­ãƒžãƒ¼ã‚¯ç”¨
]

# Configuration
@dataclass
class Config:
    """Configuration settings"""
    teams_webhook_url: str = os.getenv("TEAMS_WEBHOOK_URL", "")

    # Gmailè¨­å®š
    gmail_address: str = os.getenv("GMAIL_ADDRESS", "dummy@example.com")
    credentials_file: str = os.getenv("GMAIL_CREDENTIALS_FILE", "/workspace/NewsBot2/app/credentials/credentials.json")
    token_file: str = os.getenv("GMAIL_TOKEN_FILE", "/workspace/NewsBot2/app/credentials/token.pickle")

    # å‡¦ç†è¨­å®š
    check_hours_back: int = int(os.getenv("CHECK_HOURS_BACK_TWEET", "3"))  # Xå…±æœ‰ãƒ¡ãƒ¼ãƒ«ç”¨ï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3æ™‚é–“
    max_emails_per_run: int = int(os.getenv("MAX_EMAILS_PER_RUN", "5"))

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    process_only_unread: bool = os.getenv("PROCESS_ONLY_UNREAD", "true").lower() == "true"
    mark_as_read: bool = os.getenv("MARK_AS_READ", "true").lower() == "true"

    # LLMè¨­å®š
    llm_endpoint: str = os.getenv("LLM_ENDPOINT", "http://192.168.131.193:8008/v1/chat/completions")
    llm_model: str = os.getenv("LLM_MODEL", "gpt-3.5-turbo")

    dry_run: bool = os.getenv("DRY_RUN", "false").lower() == "true"


class GmailClient:
    """Gmail API Client for fetching X share emails"""

    def __init__(self, config: Config):
        self.config = config
        self.service = None
        self.creds = None

    def authenticate(self):
        """Gmail APIèªè¨¼"""
        token_path = Path(self.config.token_file)
        creds_path = Path(self.config.credentials_file)

        # ãƒˆãƒ¼ã‚¯ãƒ³ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯èª­ã¿è¾¼ã¿
        if token_path.exists():
            with open(token_path, 'rb') as token:
                self.creds = pickle.load(token)

        # èªè¨¼ãŒç„¡åŠ¹ã¾ãŸã¯å­˜åœ¨ã—ãªã„å ´åˆ
        if not self.creds or not self.creds.valid:
            if self.creds and self.creds.expired and self.creds.refresh_token:
                logger.info("Refreshing Gmail token...")
                self.creds.refresh(Request())
            else:
                if not creds_path.exists():
                    logger.error(f"Credentials file not found: {creds_path}")
                    logger.info("Please download credentials.json from Google Cloud Console")
                    logger.info("1. Go to https://console.cloud.google.com/")
                    logger.info("2. Create/Select project â†’ Enable Gmail API")
                    logger.info("3. Create credentials â†’ OAuth 2.0 Client ID")
                    logger.info("4. Download and save as credentials.json")
                    return False

                logger.info("Authenticating with Gmail for the first time...")
                flow = InstalledAppFlow.from_client_secrets_file(
                    str(creds_path), SCOPES
                )
                self.creds = flow.run_local_server(port=0)

            # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿å­˜
            token_path.parent.mkdir(parents=True, exist_ok=True)
            with open(token_path, 'wb') as token:
                pickle.dump(self.creds, token)

        self.service = build('gmail', 'v1', credentials=self.creds)
        # logger.info("Gmail authentication successful")  # æ¯Žåˆ†ã¯ä¸è¦
        return True

    def search_x_share_emails(self) -> List[Dict]:
        """Xå…±æœ‰ãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢"""
        if not self.service:
            return []

        try:
            # æ¤œç´¢ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            jst = pytz.timezone('Asia/Tokyo')
            after_date = datetime.now(jst) - timedelta(hours=self.config.check_hours_back)
            after_str = after_date.strftime("%Y/%m/%d")

            # è‡ªåˆ†ã‹ã‚‰è‡ªåˆ†ã¸ã®ãƒ¡ãƒ¼ãƒ«ã€X/Twitterã®URLã‚’å«ã‚€
            query_parts = [
                f"from:{self.config.gmail_address}",
                f"to:{self.config.gmail_address}",
                f"after:{after_str}",
                "(x.com OR twitter.com)"
            ]

            if self.config.process_only_unread:
                query_parts.append("is:unread")

            query = " ".join(query_parts)
            # logger.info(f"Gmail search query: {query}")  # æ¯Žå›žå‡ºåŠ›ã¯ä¸è¦

            # ãƒ¡ãƒ¼ãƒ«æ¤œç´¢ï¼ˆã™ã¹ã¦ã®å¯¾è±¡ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ï¼‰
            all_messages = []
            page_token = None

            while True:
                results = self.service.users().messages().list(
                    userId='me',
                    q=query,
                    pageToken=page_token,
                    maxResults=100  # APIã®1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®æœ€å¤§å€¤
                ).execute()

                messages = results.get('messages', [])
                all_messages.extend(messages)

                page_token = results.get('nextPageToken')
                if not page_token:
                    break

            if all_messages:  # ãƒ¡ãƒ¼ãƒ«ãŒã‚ã‚‹æ™‚ã ã‘ãƒ­ã‚°å‡ºåŠ›
                logger.info(f"Found {len(all_messages)} X share emails total")

            # å„ãƒ¡ãƒ¼ãƒ«ã®è©³ç´°ã‚’å–å¾—ï¼ˆæ™‚é–“æƒ…å ±ã‚‚å«ã‚€ï¼‰
            emails = []
            for msg in all_messages:
                email_data = self.get_email_details(msg['id'])
                if email_data:
                    emails.append(email_data)

            # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤ã„é †ï¼‰
            emails.sort(key=lambda x: x.get('internalDate', '0'))

            # è¨­å®šã•ã‚ŒãŸä¸Šé™æ•°ã®-1, 0, +1ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åŠ ç®—ã—ã¦å‡¦ç†å¯¾è±¡ã¨ã™ã‚‹
            max_count = self.config.max_emails_per_run # + random.randint(-1, 1)
            emails = emails[:max_count]

            if emails:
                logger.info(f"Processing {len(emails)} oldest emails")

            return emails

        except HttpError as e:
            logger.error(f"Gmail API error: {e}")
            return []

    def get_email_details(self, message_id: str) -> Optional[Dict]:
        """ãƒ¡ãƒ¼ãƒ«ã®è©³ç´°ã‚’å–å¾—"""
        try:
            message = self.service.users().messages().get(
                userId='me',
                id=message_id
            ).execute()

            # ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰æƒ…å ±å–å¾—
            headers = message['payload'].get('headers', [])
            subject = ""
            date = ""

            for header in headers:
                name = header['name']
                value = header['value']
                if name == 'Subject':
                    subject = value
                elif name == 'Date':
                    date = value

            # æœ¬æ–‡ã‚’å–å¾—
            body = self.extract_body(message['payload'])

            return {
                'id': message_id,
                'subject': subject,
                'date': date,
                'body': body,
                'snippet': message.get('snippet', ''),
                'internalDate': message.get('internalDate', '0')  # ã‚½ãƒ¼ãƒˆç”¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            }

        except HttpError as e:
            logger.error(f"Error getting email details: {e}")
            return None

    def extract_body(self, payload) -> str:
        """ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‚’æŠ½å‡º"""
        body = ""

        # ã‚·ãƒ³ã‚°ãƒ«ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«
        if 'body' in payload and 'data' in payload['body']:
            data = payload['body']['data']
            body = base64.urlsafe_b64decode(data).decode('utf-8', errors='ignore')

        # ãƒžãƒ«ãƒãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«
        elif 'parts' in payload:
            for part in payload['parts']:
                if part['mimeType'] == 'text/plain':
                    data = part['body']['data']
                    body += base64.urlsafe_b64decode(data).decode('utf-8', errors='ignore')
                elif 'parts' in part:  # ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ‘ãƒ¼ãƒˆ
                    body += self.extract_body(part)

        return body

    def mark_as_read(self, message_id: str):
        """ãƒ¡ãƒ¼ãƒ«ã‚’æ—¢èª­ã«ã™ã‚‹"""
        if self.config.dry_run:
            logger.info(f"DRY RUN - Would mark email as read: {message_id}")
            return

        try:
            self.service.users().messages().modify(
                userId='me',
                id=message_id,
                body={'removeLabelIds': ['UNREAD']}
            ).execute()
            logger.info(f"Marked email as read: {message_id}")
        except HttpError as e:
            logger.error(f"Error marking email as read: {e}")


class XShareParser:
    """Xå…±æœ‰ãƒ¡ãƒ¼ãƒ«ã®è§£æž"""

    def extract_x_info(self, email: Dict) -> Optional[Dict]:
        """ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰XæŠ•ç¨¿æƒ…å ±ã‚’æŠ½å‡º"""

        body = email.get('body', '')
        subject = email.get('subject', '')

        # ãƒ‡ãƒãƒƒã‚°ï¼šãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã®æœ€åˆã®500æ–‡å­—ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆå¿…è¦æ™‚ã®ã¿æœ‰åŠ¹åŒ–ï¼‰
        # logger.debug(f"Email body preview: {body[:500]}...")
        # logger.debug(f"Email subject: {subject}")

        # X/Twitterã®URLã‚’æŠ½å‡º
        url_pattern = r'https?://(?:www\.)?(?:twitter\.com|x\.com)/(\w+)/status/(\d+)'
        url_match = re.search(url_pattern, body + ' ' + subject)

        if not url_match:
            logger.warning("No X/Twitter URL found in email")
            return None

        username = url_match.group(1)
        tweet_id = url_match.group(2)
        url = url_match.group(0)

        # æœ¬æ–‡ã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆæ”¹å–„ç‰ˆï¼‰
        tweet_text = ""

        # æ–¹æ³•1: URLã®å‰ã®éƒ¨åˆ†ã‹ã‚‰å–å¾—
        text_before_url = body.split(url)[0].strip()

        # æ–¹æ³•2: å…¨ä½“ã‹ã‚‰å…±æœ‰ãƒ¡ãƒ¼ãƒ«ã®å®šåž‹æ–‡ã‚’é™¤åŽ»
        full_text = body

        # Gmailå…±æœ‰ã®ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤åŽ»
        clean_patterns = [
            r'Check out.*?:\s*',
            r'Shared from.*?:\s*',
            r'From X.*?:\s*',
            r'.*shared.*tweet.*:\s*',
            r'---------- Forwarded message ---------.*?\n',
            r'From:.*?\n',
            r'Date:.*?\n',
            r'Subject:.*?\n',
            r'To:.*?\n'
        ]

        for pattern in clean_patterns:
            text_before_url = re.sub(pattern, '', text_before_url, flags=re.IGNORECASE | re.DOTALL)
            full_text = re.sub(pattern, '', full_text, flags=re.IGNORECASE | re.DOTALL)

        # URLã¨ãã®å¾Œã®ä½™è¨ˆãªéƒ¨åˆ†ã‚’å‰Šé™¤
        full_text = re.sub(r'https?://(?:www\.)?(?:twitter\.com|x\.com)/\S+.*', '', full_text, flags=re.DOTALL)
        # t.coçŸ­ç¸®URLã‚’å‰Šé™¤
        full_text = re.sub(r'https?://t\.co/\S+', '', full_text)

        # ã€Œãƒã‚¹ãƒˆã—ã¾ã—ãŸ:ã€ã¾ã§ã®éƒ¨åˆ†ã‚’å‰Šé™¤
        if 'ãƒã‚¹ãƒˆã—ã¾ã—ãŸ:' in full_text:
            # ã€Œãƒã‚¹ãƒˆã—ã¾ã—ãŸ:ã€ã®å¾Œã®éƒ¨åˆ†ã®ã¿ã‚’å–å¾—
            full_text = full_text.split('ãƒã‚¹ãƒˆã—ã¾ã—ãŸ:', 1)[-1]
            # å…ˆé ­ã®ç©ºç™½æ–‡å­—ï¼ˆæ”¹è¡Œã€ã‚¹ãƒšãƒ¼ã‚¹ã€ã‚¿ãƒ–ãªã©ï¼‰ã‚’å‰Šé™¤
            full_text = full_text.lstrip()

        # æ”¹è¡Œã§åˆ†å‰²ã—ã€æ„å‘³ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’æŽ¢ã™
        lines = full_text.strip().split('\n')
        meaningful_lines = []

        for line in lines:
            line = line.strip()
            # ç©ºè¡Œã‚„çŸ­ã™ãŽã‚‹è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            if line and len(line) > 3 and not line.startswith('--'):
                meaningful_lines.append(line)

        # è¤‡æ•°è¡Œã®ãƒ„ã‚¤ãƒ¼ãƒˆã«å¯¾å¿œ
        if meaningful_lines:
            tweet_text = '\n'.join(meaningful_lines[:10])  # æœ€å¤§10è¡Œã¾ã§å–å¾—

        # ãƒ„ã‚¤ãƒ¼ãƒˆãƒ†ã‚­ã‚¹ãƒˆãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not tweet_text.strip():
            tweet_text = "[ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‹ã‚‰æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ]"
            logger.warning(f"Could not extract tweet text from email. Body length: {len(body)}")

        # logger.info(f"Extracted tweet text: {tweet_text[:100]}...")  # ãƒ‡ãƒãƒƒã‚°ç”¨

        return {
            'url': url,
            'username': username,
            'tweet_id': tweet_id,
            'text': tweet_text[:500],  # é•·ã‚ã«å–å¾—ï¼ˆTeamsã‚«ãƒ¼ãƒ‰ã§è¡¨ç¤ºèª¿æ•´ï¼‰
            'date': email.get('date', ''),
            'email_id': email.get('id', '')
        }


# ä¸è¦ãªNewsCollectorã¨NewsFilterã‚¯ãƒ©ã‚¹ã¯å‰Šé™¤æ¸ˆã¿

class TextRewriter:
    """LLMã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’é­…åŠ›çš„ã«æ›¸ãæ›ãˆ"""

    def __init__(self, config: Config):
        self.config = config
        self.endpoint = config.llm_endpoint
        self.model = config.llm_model

    def rewrite_text(self, original_text: str) -> str:
        """
        å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è‘—ä½œæ¨©ã«é…æ…®ã—ã¤ã¤é­…åŠ›çš„ã«æ›¸ãæ›ãˆã‚‹
        äº‹å®Ÿé–¢ä¿‚ã¯åŽ³å¯†ã«ä¿æŒã™ã‚‹
        """
        if not original_text or original_text.strip() == "[ãƒ¡ãƒ‡ã‚£ã‚¢ã®ã¿ã®æŠ•ç¨¿]":
            return original_text

        if not self.endpoint:
            logger.warning("LLM endpoint not configured, using original text")
            return original_text

        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            system_prompt = """ã‚ãªãŸã¯Twitterã§è©±é¡Œã‚’ç´¹ä»‹ã™ã‚‹äººã§ã™ã€‚
å…ƒã®å†…å®¹ã‚’ã€çŸ­ãé­…åŠ›çš„ãªç´¹ä»‹ãƒ„ã‚¤ãƒ¼ãƒˆã«å¤‰æ›ã—ã¦ãã ã•ã„ï¼š

ãƒ«ãƒ¼ãƒ«ï¼š
1. äº‹å®Ÿãƒ»æ•°å€¤ã¯æ­£ç¢ºã«ä¿æŒï¼ˆå¤‰ãˆãªã„ãƒ»æ¸›ã‚‰ã•ãªã„ãƒ»å¢—ã‚„ã•ãªã„ï¼‰
2. å…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’140æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«ç´¹ä»‹
3. ã€Œã€œã ã£ã¦ã€ã€Œã€œã‚‰ã—ã„ã€ã€Œã€œã¿ãŸã„ã€ãªã©å£èªžçš„è¡¨ç¾OK
4. çµµæ–‡å­—ã‚’åŠ¹æžœçš„ã«ä½¿ç”¨
5. èˆˆå‘³ã‚’å¼•ãä¸€è¨€ã‹ã‚‰å§‹ã‚ã‚‹
6. ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã¯ç¦æ­¢"""

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            user_prompt = f"""ã“ã‚Œã‚’çŸ­ãç´¹ä»‹ï¼š

{original_text}

ç´¹ä»‹ãƒ„ã‚¤ãƒ¼ãƒˆï¼š"""

            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®ä½œæˆ
            request_body = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 500
            }

            # LLMã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = requests.post(
                self.endpoint,
                headers={"Content-Type": "application/json"},
                json=request_body,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    rewritten_text = result["choices"][0]["message"]["content"].strip()
                    logger.info("Text successfully rewritten by LLM")
                    return rewritten_text
                else:
                    logger.warning("Unexpected LLM response format")
                    return original_text
            else:
                logger.error(f"LLM request failed with status {response.status_code}: {response.text}")
                return original_text

        except requests.exceptions.Timeout:
            logger.error("LLM request timeout")
            return original_text
        except Exception as e:
            logger.error(f"Error rewriting text with LLM: {e}")
            return original_text

class TeamsPublisher:
    """Xå…±æœ‰ã‚’Microsoft Teamsã«æŠ•ç¨¿"""

    def __init__(self, config: Config):
        self.config = config
        self.text_rewriter = TextRewriter(config)

    def create_x_share_card(self, x_info: Dict) -> Dict:
        """Xå…±æœ‰ç”¨ã®Adaptive Cardä½œæˆ"""

        # ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®å ´åˆ
        original_text = x_info['text'] if x_info['text'] else "[ãƒ¡ãƒ‡ã‚£ã‚¢ã®ã¿ã®æŠ•ç¨¿]"

        # LLMã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›¸ãæ›ãˆ
        text_display = self.text_rewriter.rewrite_text(original_text)

        # æ›¸ãæ›ãˆãŒå¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
        if not text_display:
            text_display = original_text

        # Adaptive Cardã§æ”¹è¡Œã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã€\nã‚’\n\nã«å¤‰æ›ï¼ˆMarkdownã§ã®æ”¹è¡Œï¼‰
        # ã¾ãŸã€Teamsã®Adaptive Cardã§ã¯2ã¤ã®æ”¹è¡ŒãŒå¿…è¦
        text_display = text_display.replace('\n', '\n\n')

        # ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—ï¼ˆJSTï¼‰
        jst = pytz.timezone('Asia/Tokyo')
        now = datetime.now(jst)
        time_str = now.strftime("%Y/%m/%d %H:%M:%S")

        return {
            "type": "message",
            "attachments": [{
                "contentType": "application/vnd.microsoft.card.adaptive",
                "content": {
                    "type": "AdaptiveCard",
                    "version": "1.2",
                    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
                    "body": [
                        {
                            "type": "TextBlock",
                            "text": f"ðŸ¦ AI News form X - {time_str}",
                            "size": "Large",
                            "weight": "Bolder",
                            "color": "Accent"
                        },
                        {
                            "type": "TextBlock",
                            "text": f"@{x_info['username']} ã®æŠ•ç¨¿ã«åŸºã¥ãAIç´¹ä»‹æ–‡",
                            "size": "Medium",
                            "color": "Good",
                            "spacing": "Small"
                        },
                        {
                            "type": "TextBlock",
                            "text": text_display,
                            "wrap": True,
                            "size": "Medium",
                            "spacing": "Medium"
                        }
                    ],
                    "actions": [
                        {
                            "type": "Action.OpenUrl",
                            "title": "Xã§é–‹ã ðŸ”—",
                            "url": x_info['url']
                        }
                    ]
                }
            }]
        }

    def post_to_teams(self, x_info: Dict) -> bool:
        """Teamsã«æŠ•ç¨¿"""

        card = self.create_x_share_card(x_info)

        if self.config.dry_run:
            logger.info(f"DRY RUN - Would post to Teams: @{x_info['username']} - {x_info['text'][:50]}...")
            return True

        try:
            response = requests.post(
                self.config.teams_webhook_url,
                json=card,
                timeout=10
            )

            if response.status_code in [200, 202, 1]:
                logger.info(f"Posted to Teams: @{x_info['username']} - {x_info['tweet_id']}")
                return True
            else:
                logger.error(f"Failed to post to Teams: {response.status_code}")
                return False

        except Exception as e:
            logger.error(f"Error posting to Teams: {e}")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""

    # logger.info("=== X Gmail Share to Teams Bridge Started ===")  # æ¯Žåˆ†ã¯ä¸è¦

    config = Config()

    if config.dry_run:
        logger.info("Running in DRY RUN mode")

    # Gmailèªè¨¼
    gmail = GmailClient(config)
    if not gmail.authenticate():
        logger.error("Gmail authentication failed")
        return 1

    # Xå…±æœ‰ãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢
    emails = gmail.search_x_share_emails()

    if not emails:
        # logger.info("No X share emails found")  # æ¯Žåˆ†ã¯ä¸è¦
        return 0

    # ãƒ‘ãƒ¼ã‚µãƒ¼ã¨ãƒ‘ãƒ–ãƒªãƒƒã‚·ãƒ£ãƒ¼åˆæœŸåŒ–
    parser = XShareParser()
    publisher = TeamsPublisher(config)

    posted_count = 0

    # å„ãƒ¡ãƒ¼ãƒ«ã‚’å‡¦ç†
    for email in emails:
        logger.info(f"Processing email: {email.get('subject', '')[:50]}...")

        # ãƒ‡ãƒãƒƒã‚°ï¼šãƒ¡ãƒ¼ãƒ«å†…å®¹å…¨æ–‡ã‚’å‡ºåŠ›
        logger.info("=" * 60)
        logger.info("ã€ãƒ¡ãƒ¼ãƒ«å†…å®¹å…¨æ–‡ã€‘")
        logger.info("=" * 60)
        logger.info(f"Subject: {email.get('subject', '')}")
        logger.info(f"Date: {email.get('date', '')}")
        logger.info("Body:")
        logger.info(email.get('body', ''))
        logger.info("=" * 60)

        # Xæƒ…å ±ã‚’æŠ½å‡º
        x_info = parser.extract_x_info(email)

        if not x_info:
            logger.warning("Could not extract X info from email")
            continue

        # ãƒ‡ãƒãƒƒã‚°ï¼šæŠ•ç¨¿å†…å®¹å…¨æ–‡ã‚’å‡ºåŠ›
        logger.info("=" * 60)
        logger.info("ã€TeamsæŠ•ç¨¿å†…å®¹ã€‘")
        logger.info("=" * 60)
        logger.info(f"URL: {x_info['url']}")
        logger.info(f"Username: @{x_info['username']}")
        logger.info(f"Tweet ID: {x_info['tweet_id']}")
        logger.info(f"Text:\n{x_info['text']}")
        logger.info("=" * 60)

        # Teamsã«æŠ•ç¨¿
        if publisher.post_to_teams(x_info):
            posted_count += 1

            # æˆåŠŸã—ãŸã‚‰æ—¢èª­ã«ã™ã‚‹
            if config.mark_as_read:
                gmail.mark_as_read(email['id'])

    if posted_count > 0:
        logger.info(f"Posted {posted_count} X shares to Teams")
    return 0 if posted_count > 0 else 1

if __name__ == "__main__":
    exit(main())